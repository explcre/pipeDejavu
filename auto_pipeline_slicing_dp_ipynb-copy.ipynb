{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/explcre/pipeDejavu/blob/main/auto_pipeline_slicing_dp_ipynb-copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define a simple input tensor with 7 elements\n",
        "x = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0], requires_grad=True)\n",
        "\n",
        "# Apply the max operation on the input tensor\n",
        "max_value, max_idx = torch.max(x,dim=0)\n",
        "\n",
        "# Define the loss function as the max value\n",
        "loss = max_value\n",
        "\n",
        "# Compute the gradients\n",
        "loss.backward()\n",
        "\n",
        "# Print the gradients with respect to the input tensor\n",
        "print(\"Gradients: \", x.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C84lnwV3YjXK",
        "outputId": "59e4aed0-253d-4db6-d761-99f3bc180136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients:  tensor([0., 0., 0., 0., 0., 0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numba\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsjpejO9d2am",
        "outputId": "1a3ca3fa-2dc4-4850-d3b0-d4030caaa7af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.56.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba) (67.7.2)\n",
            "Requirement already satisfied: numpy<1.24,>=1.18 in /usr/local/lib/python3.10/dist-packages (from numba) (1.22.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.39.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cupy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzzwEIlId5zy",
        "outputId": "8221a8d3-864d-45f9-b931-6c0c63301799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cupy\n",
            "  Using cached cupy-12.0.0.tar.gz (2.0 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<1.27,>=1.20 in /usr/local/lib/python3.10/dist-packages (from cupy) (1.22.4)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy) (0.8.1)\n",
            "Building wheels for collected packages: cupy\n",
            "  Building wheel for cupy (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 160, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 241, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 463, in run\n",
            "    _, build_failures = build(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 347, in build\n",
            "    wheel_file = _build_one(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 221, in _build_one\n",
            "    wheel_path = _build_one_inside_env(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 268, in _build_one_inside_env\n",
            "    wheel_path = build_wheel_legacy(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/build/wheel_legacy.py\", line 83, in build_wheel_legacy\n",
            "    output = call_subprocess(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/subprocess.py\", line 166, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 214, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 197, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "1MdvGw37LQRH"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import itertools\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "from numba import jit, prange"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xbpjSBHVQ3t",
        "outputId": "8ad28114-ab63-4fe9-8bde-fc77dcafa0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun May  7 03:19:53 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbCfjNagLQRK"
      },
      "outputs": [],
      "source": [
        "# simplification\n",
        "def f(L, maxl, cost, k, B):\n",
        "    if k == 1:\n",
        "        return ([L], B*max(0, L-maxl))\n",
        "    if k == L:\n",
        "        cost_ = max(1, maxl) * B\n",
        "        for i in range(k-1):\n",
        "         #   cost_ += cost[i][i]\n",
        "            cost_ += cost[i]\n",
        "        return ([1] * L, cost_)\n",
        "    \n",
        "    cost_best = float(\"inf\")\n",
        "    S_best = []\n",
        "    for i in reversed(range(k, L)):\n",
        "        S, cost_ = f(i, max(L-i, maxl), cost, k-1, B)\n",
        "        cost_ += max(0, L-i-maxl)*B\n",
        "        cost_ += cost[i-1]\n",
        "        if cost_ < cost_best:\n",
        "            cost_best = cost_\n",
        "            S.append(L-i)\n",
        "            S_best = S\n",
        "    return S_best, cost_best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffYWtK1eLQRL",
        "outputId": "4dfb9916-30af-43b0-cd22-552c77613645"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([2, 1, 2, 2, 2, 1, 1, 1], 15)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "L = 12\n",
        "k = 8\n",
        "cost = [2,1,1,3] * 12\n",
        "f(L, 0, cost, k, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "aSgUxlfPLQRL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "d42fd6ca-4653-4568-869f-18f682bd6a61"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-162a65898a6f>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnopython\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpipe_dp_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mpossible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'jit' is not defined"
          ]
        }
      ],
      "source": [
        "#@jit(nopython=True)\n",
        "def pipe_dp(L, cost_e, cost_c, k, B):\n",
        "    # Generate all possible max length\n",
        "    possible = [0]\n",
        "    \n",
        "    for i in range(1, L+1):\n",
        "        ptr = 0\n",
        "        while ptr + i <= L:\n",
        "            possible.append(sum(cost_e[ptr:ptr+i]))\n",
        "            ptr += 1\n",
        "    \n",
        "    possible = sorted(list(set(possible)))\n",
        "    # print(possible)\n",
        "    # trace will be a 3D list\n",
        "    trace = []\n",
        "    for i in range(L):\n",
        "        outer = []\n",
        "        for j in range(k):\n",
        "            inner = []\n",
        "            for m in range(len(possible)):\n",
        "                inner.append(([],np.infty))\n",
        "            outer.append(inner)\n",
        "        trace.append(outer)\n",
        "    \n",
        "    # i: layer id, starting from 0\n",
        "    # j: number of cut (=GPU-1)\n",
        "    for i in range(L):\n",
        "        for j in range(k):\n",
        "            for m in range(len(possible)):\n",
        "                if i+1 <= j: # invalid\n",
        "                    pass\n",
        "                else:\n",
        "                    if j == 0: # base case: 0 cut\n",
        "                        cur_sum = sum(cost_e[:i+1])\n",
        "                        assert cur_sum in possible\n",
        "                        trace[i][j][m] = ([i+1], (B-1) * max(0, cur_sum - possible[m]))\n",
        "                    else:\n",
        "                        cost_best = np.infty\n",
        "                        S_best = []\n",
        "                        for cut in range(j-1, i):\n",
        "                            cur_sum = sum(cost_e[cut+1:i+1])\n",
        "                            assert cur_sum in possible\n",
        "                            S, cost_ = trace[cut][j-1][possible.index(max(cur_sum, possible[m]))]\n",
        "                            #print(S, cost_)\n",
        "                            cost_ += (B-1) * max(0, cur_sum - possible[m])\n",
        "                            cost_ += cost_c[cut][j-1]\n",
        "                            if cost_ < cost_best:\n",
        "                                cost_best = cost_\n",
        "                                S_ = copy.deepcopy(S)\n",
        "                                S_.append(i-cut)\n",
        "                                S_best = S_\n",
        "                        trace[i][j][m] = (S_best, cost_best)\n",
        "                        \n",
        "    for i in range(L):\n",
        "        for j in range(k):\n",
        "            pass\n",
        "            #print(i, j, trace[i][j])\n",
        "    return trace[L-1][k-1][0]\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def pipe_dp_v2(L, cost_e, cost_c, k, B):\n",
        "    possible = np.zeros(L + 1, dtype=np.int64)\n",
        "\n",
        "    for i in range(1, L + 1):\n",
        "        ptr = 0\n",
        "        while ptr + i <= L:\n",
        "            possible[ptr + i - 1] = sum(cost_e[ptr:ptr + i])\n",
        "            ptr += 1\n",
        "\n",
        "    possible = np.unique(possible)\n",
        "\n",
        "    trace = np.empty((L, k, possible.shape[0]), dtype=np.object_)\n",
        "\n",
        "    for i in range(L):\n",
        "        for j in range(k):\n",
        "            for m in range(possible.shape[0]):\n",
        "                if i + 1 <= j:\n",
        "                    pass\n",
        "                else:\n",
        "                    if j == 0:\n",
        "                        cur_sum = sum(cost_e[:i + 1])\n",
        "                        trace[i, j, m] = (np.array([i + 1], dtype=np.int64), (B - 1) * max(0, cur_sum - possible[m]))\n",
        "                    else:\n",
        "                        cost_best = np.inf\n",
        "                        S_best = np.empty(0, dtype=np.int64)\n",
        "                        for cut in range(j - 1, i):\n",
        "                            cur_sum = sum(cost_e[cut + 1:i + 1])\n",
        "                            S, cost_ = trace[cut, j - 1, np.where(possible == max(cur_sum, possible[m]))[0][0]]\n",
        "                            cost_ += (B - 1) * max(0, cur_sum - possible[m])\n",
        "                            cost_ += cost_c[cut, j - 1]\n",
        "                            if cost_ < cost_best:\n",
        "                                cost_best = cost_\n",
        "                                S_ = S.copy()\n",
        "                                S_best = np.append(S_, i - cut)\n",
        "                        trace[i, j, m] = (S_best, cost_best)\n",
        "\n",
        "    return trace[L - 1, k - 1, 0]\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def pipe_dp_v3(L, cost_e, cost_c, k, B):\n",
        "    possible = np.zeros(L + 1, dtype=np.int64)\n",
        "\n",
        "    for i in range(1, L + 1):\n",
        "        ptr = 0\n",
        "        while ptr + i <= L:\n",
        "            possible[ptr + i - 1] = sum(cost_e[ptr:ptr + i])\n",
        "            ptr += 1\n",
        "\n",
        "    possible = np.unique(possible)\n",
        "\n",
        "    trace = np.empty((L, k, possible.shape[0]), dtype=np.object_)\n",
        "\n",
        "    for i in range(L):\n",
        "        for j in range(k):\n",
        "            for m in range(possible.shape[0]):\n",
        "                if i + 1 <= j:\n",
        "                    pass\n",
        "                else:\n",
        "                    if j == 0:\n",
        "                        cur_sum = sum(cost_e[:i + 1])\n",
        "                        trace[i, j, m] = (np.array([i + 1], dtype=np.int64), (B - 1) * max(0, cur_sum - possible[m]))\n",
        "                    else:\n",
        "                        cost_best = np.inf\n",
        "                        S_best = np.empty(0, dtype=np.int64)\n",
        "                        for cut in range(j - 1, i):\n",
        "                            cur_sum = sum(cost_e[cut + 1:i + 1])\n",
        "                            S, cost_ = trace[cut, j - 1, np.where(possible == max(cur_sum, possible[m]))[0][0]]\n",
        "                            cost_ += (B - 1) * max(0, cur_sum - possible[m])\n",
        "                            cost_ += cost_c[cut, j - 1]\n",
        "                            if cost_ < cost_best:\n",
        "                                cost_best = cost_\n",
        "                                S_ = S.copy()\n",
        "                                S_best = np.append(S_, i - cut)\n",
        "                        trace[i, j, m] = (S_best, cost_best)\n",
        "\n",
        "    return trace[L - 1, k - 1, 0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def pipe_dp_v4(L, cost_e, cost_c, k, B):\n",
        "    possible = np.zeros(L + 1, dtype=np.int64)\n",
        "\n",
        "    for i in range(1, L + 1):\n",
        "        ptr = 0\n",
        "        while ptr + i <= L:\n",
        "            possible[ptr + i - 1] = sum(cost_e[ptr:ptr + i])\n",
        "            ptr += 1\n",
        "\n",
        "    possible = np.unique(possible)\n",
        "\n",
        "    trace_S = np.empty((L, k, possible.shape[0]), dtype=np.int64)\n",
        "    trace_cost = np.full((L, k, possible.shape[0]), np.inf)\n",
        "\n",
        "    for i in range(L):\n",
        "        for j in range(k):\n",
        "            for m in range(possible.shape[0]):\n",
        "                if i + 1 <= j:\n",
        "                    pass\n",
        "                else:\n",
        "                    if j == 0:\n",
        "                        cur_sum = sum(cost_e[:i + 1])\n",
        "                        trace_S[i, j, m] = i + 1\n",
        "                        trace_cost[i, j, m] = (B - 1) * max(0, cur_sum - possible[m])\n",
        "                    else:\n",
        "                        cost_best = np.inf\n",
        "                        S_best = -1\n",
        "                        for cut in range(j - 1, i):\n",
        "                            cur_sum = sum(cost_e[cut + 1:i + 1])\n",
        "                            S, cost_ = trace_S[cut, j - 1, np.where(possible == max(cur_sum, possible[m]))[0][0]], trace_cost[cut, j - 1, np.where(possible == max(cur_sum, possible[m]))[0][0]]\n",
        "                            cost_ += (B - 1) * max(0, cur_sum - possible[m])\n",
        "                            cost_ += cost_c[cut, j - 1]\n",
        "                            if cost_ < cost_best:\n",
        "                                cost_best = cost_\n",
        "                                S_best = S\n",
        "                        trace_S[i, j, m] = S_best\n",
        "                        trace_cost[i, j, m] = cost_best\n",
        "\n",
        "    return trace_S[L - 1, k - 1], trace_cost[L - 1, k - 1]\n",
        "\n",
        "\n",
        "\n",
        "#@jit(nopython=True)\n",
        "def brute_force(L, cost_e, cost_c, k, B):\n",
        "    best_S = []\n",
        "    best_cost = np.infty\n",
        "    ptr_done = [0] * (k-1)\n",
        "    possible = list(itertools.combinations(range(L-1), k-1))\n",
        "    for p in possible:\n",
        "        p = list(p)\n",
        "        p.append(L-1)\n",
        "        lens = [sum(cost_e[:p[0]+1])]\n",
        "        s = [p[0]+1]\n",
        "        for i in range(len(p)-1):\n",
        "            lens.append(sum(cost_e[p[i]+1:p[i+1]+1]))\n",
        "            s.append(p[i+1]-p[i])     \n",
        "        max_l = max(lens)\n",
        "        cost = (B-1) * max_l\n",
        "        for i in range(k-1):\n",
        "            cost += cost_c[p[i]][i]\n",
        "        if cost < best_cost:\n",
        "            best_cost = cost\n",
        "            best_S = s\n",
        "    return best_S, best_cost\n",
        "\n",
        "#@jit(nopython=True)\n",
        "def uniform_split(L, cost_e, cost_c, k, B):\n",
        "    per_stage = L // k\n",
        "    \n",
        "    s = [per_stage] * (k-1)\n",
        "    s.append(L-sum(s))\n",
        "    p = [s[0]-1]\n",
        "    for i in range(1, k):\n",
        "        p.append(p[i-1] + s[i])\n",
        "    lens = [sum(cost_e[:p[0]+1])]\n",
        "    for i in range(len(s)-1):\n",
        "        lens.append(sum(cost_e[p[i]+1:p[i+1]+1]))\n",
        "    max_l = max(lens)\n",
        "    cost = (B-1) * max_l\n",
        "    for i in range(k-1):\n",
        "        cost += cost_c[p[i]][i]\n",
        "    return s, cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "SBDBuHKRLQRM",
        "outputId": "c91d65e6-1953-42b8-9140-3662cbdc7ede"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-06f6ef3686df>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#cost_e = [1,3,2,5]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcost_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpipe_dp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pipe_dp' is not defined"
          ]
        }
      ],
      "source": [
        "L = 4\n",
        "k = 2\n",
        "cost_e = np.array([1, 3, 2, 5])\n",
        "#cost_e = [1,3,2,5]\n",
        "cost_c = np.ones((L-1, k-1)) * 2\n",
        "pipe_dp(L, cost_e, cost_c, k, 3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "def replace_nan(tensor, value=1e-6):\n",
        "    return torch.where(torch.isnan(tensor), torch.full_like(tensor, value), tensor)\n",
        "\n",
        "\n",
        "def softargmax2d(input, beta=100):\n",
        "    *_, h, w = input.shape\n",
        "    \n",
        "    input = input.reshape(*_, h * w)\n",
        "    input = replace_nan(input)  # Add this line\n",
        "    input = nn.functional.softmax(beta * input, dim=-1)\n",
        "\n",
        "    indices_c, indices_r = np.meshgrid(\n",
        "        np.linspace(0, 1, w),\n",
        "        np.linspace(0, 1, h),\n",
        "        indexing='xy'\n",
        "    )\n",
        "\n",
        "    indices_r = torch.tensor(np.reshape(indices_r, (-1, h * w)))\n",
        "    indices_c = torch.tensor(np.reshape(indices_c, (-1, h * w)))\n",
        "\n",
        "    result_r = torch.sum((h - 1) * input * indices_r, dim=-1)\n",
        "    result_c = torch.sum((w - 1) * input * indices_c, dim=-1)\n",
        "\n",
        "    result = torch.stack([result_r, result_c], dim=-1)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "MqyGXyMLkzjf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "\n",
        "\n",
        "def pipe_dp_differentiable(L, cost_e, cost_c, k, B,position):\n",
        "    # Generate all possible max length\n",
        "    possible = [0]\n",
        "\n",
        "    for i in range(1, L + 1):\n",
        "        ptr = 0\n",
        "        while ptr + i <= L:\n",
        "            possible.append(sum(cost_e[ptr:ptr + i]))\n",
        "            ptr += 1\n",
        "\n",
        "    possible = sorted(list(set(possible)))\n",
        "\n",
        "    # trace will be a 3D list\n",
        "    trace = []\n",
        "    for i in range(L):\n",
        "        outer = []\n",
        "        for j in range(k):\n",
        "            inner = []\n",
        "            for m in range(len(possible)):\n",
        "                inner.append(([], torch.tensor(float('inf'))))\n",
        "            outer.append(inner)\n",
        "        trace.append(outer)\n",
        "\n",
        "    # i: layer id, starting from 0\n",
        "    # j: number of cut (=GPU-1)\n",
        "    for i in range(L):\n",
        "        for j in range(k):\n",
        "            for m in range(len(possible)):\n",
        "                if i + 1 <= j:  # invalid\n",
        "                    pass\n",
        "                else:\n",
        "                    if j == 0:  # base case: 0 cut\n",
        "                        cur_sum = sum(cost_e[:i + 1])\n",
        "                        trace[i][j][m] = ([i + 1], (B - 1) * max(0, cur_sum - possible[m]))\n",
        "                    else:\n",
        "                        cost_best = torch.tensor(float('inf'))\n",
        "                        S_best = []\n",
        "                        for cut in range(j - 1, i):\n",
        "                            cur_sum = sum(cost_e[cut + 1:i + 1])\n",
        "                            S, cost_ = trace[cut][j - 1][possible.index(max(cur_sum, possible[m]))]\n",
        "                            cost_ += (B - 1) * max(0, cur_sum - possible[m])\n",
        "                            cost_ += cost_c[cut][j - 1]\n",
        "                            if cost_ < cost_best:\n",
        "                                cost_best = cost_\n",
        "                                S_ = copy.deepcopy(S)\n",
        "                                S_.append(i - cut)\n",
        "                                S_best = S_\n",
        "                        trace[i][j][m] = (S_best, cost_best)\n",
        "\n",
        "    # Replace the non-differentiable control-flow statements with softargmax2d\n",
        "    \n",
        "    \n",
        "    cost_matrix = torch.zeros((L, k, len(possible)))\n",
        "    for i in range(L):\n",
        "        for j in range(k):\n",
        "            for m in range(len(possible)):\n",
        "                cost_matrix[i, j, m] = trace[i][j][m][1]\n",
        "    softargmax_result = softargmax2d(cost_matrix)\n",
        "    softargmax_result=replace_nan(softargmax_result)\n",
        "    \n",
        "    '''\n",
        "    if cost_matrix is None:\n",
        "        cost_matrix = torch.zeros((L, k, len(possible)))\n",
        "        for i in range(L):\n",
        "            for j in range(k):\n",
        "                for m in range(len(possible)):\n",
        "                    cost_matrix[i, j, m] = trace[i][j][m][1]\n",
        "\n",
        "    softargmax_result = softargmax2d(cost_matrix)\n",
        "    softargmax_result = replace_nan(softargmax_result)\n",
        "    '''\n",
        "    \n",
        "    # Compute the loss using the softargmax_result\n",
        "    i = int(softargmax_result[0, 0].item())\n",
        "    j = int(softargmax_result[0, 1].item())\n",
        "    m = possible.index(max(sum(cost_e[i + 1:j + 1]), possible[j]))\n",
        "    #loss = trace[i][j][m][1]\n",
        "    loss = trace[i][j][m][1] + position[i, j, m]\n",
        "\n",
        "    return softargmax_result, loss\n",
        "\n",
        "\n",
        "def pipe_dp_differentiable_original(L, cost_e, cost_c, k, B):\n",
        "    cost_e = torch.tensor(cost_e, requires_grad=True, dtype=torch.float32)\n",
        "    cost_c = torch.tensor(cost_c, requires_grad=True, dtype=torch.float32)\n",
        "\n",
        "    # Generate all possible max length\n",
        "    possible = [0]\n",
        "    for i in range(1, L+1):\n",
        "        ptr = 0\n",
        "        while ptr + i <= L:\n",
        "            possible.append(torch.sum(cost_e[ptr:ptr+i]).item())\n",
        "            ptr += 1\n",
        "    possible = sorted(list(set(possible)))\n",
        "    possible = torch.tensor(possible, dtype=torch.float32)\n",
        "\n",
        "    trace = []\n",
        "    for i in range(L):\n",
        "        outer = []\n",
        "        for j in range(k):\n",
        "            inner = []\n",
        "            for m in range(len(possible)):\n",
        "                inner.append(([], torch.tensor(np.inf, dtype=torch.float32)))\n",
        "            outer.append(inner)\n",
        "        trace.append(outer)\n",
        "\n",
        "    for i in range(L):\n",
        "        for j in range(k):\n",
        "            for m in range(len(possible)):\n",
        "                if i+1 <= j: # invalid\n",
        "                    pass\n",
        "                else:\n",
        "                    if j == 0: # base case: 0 cut\n",
        "                        cur_sum = torch.sum(cost_e[:i+1])\n",
        "                        assert cur_sum.item() in possible\n",
        "                        trace[i][j][m] = ([i+1], (B-1) * torch.relu(cur_sum - possible[m]))\n",
        "                    else:\n",
        "                        cost_best = torch.tensor(np.inf, dtype=torch.float32)\n",
        "                        S_best = []\n",
        "                        for cut in range(j-1, i):\n",
        "                            cur_sum = torch.sum(cost_e[cut+1:i+1])\n",
        "                            assert cur_sum.item() in possible\n",
        "                            S, cost_ = trace[cut][j-1][torch.where(possible == torch.max(cur_sum, possible[m]))[0]]\n",
        "                            cost_ += (B-1) * torch.relu(cur_sum - possible[m])\n",
        "                            cost_ += cost_c[cut][j-1]\n",
        "                            if cost_ < cost_best:\n",
        "                                cost_best = cost_\n",
        "                                S_ = copy.deepcopy(S)\n",
        "                                S_.append(i-cut)\n",
        "                                S_best = S_\n",
        "                        trace[i][j][m] = (S_best, cost_best)\n",
        "\n",
        "    result_S, loss = trace[L-1][k-1][0]\n",
        "    return result_S, loss\n",
        "\n"
      ],
      "metadata": {
        "id": "ycspvgOrbgDJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "\n",
        "# Parameters\n",
        "L = 4\n",
        "k = 2\n",
        "cost_e = np.array([1, 3, 2, 5])\n",
        "cost_c = np.ones((L - 1, k - 1)) * 2\n",
        "B = 3\n",
        "\n",
        "# Convert to tensors\n",
        "cost_e_tensor = torch.tensor(cost_e, dtype=torch.float32)\n",
        "cost_c_tensor = torch.tensor(cost_c, dtype=torch.float32)\n",
        "\n",
        "# Generate all possible max length\n",
        "possible = [0]\n",
        "for i in range(1, L + 1):\n",
        "    ptr = 0\n",
        "    while ptr + i <= L:\n",
        "        possible.append(sum(cost_e[ptr:ptr + i]))\n",
        "        ptr += 1\n",
        "possible = sorted(list(set(possible)))\n",
        "\n",
        "\n",
        "# Initialize position tensor\n",
        "position = torch.zeros((L, k, len(possible)), requires_grad=True)\n",
        "\n",
        "# Training parameters\n",
        "epochs = 5000\n",
        "lr = 1e-2\n",
        "optimizer = optim.SGD([position], lr=lr)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    # Zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Compute cost matrix based on the current position tensor\n",
        "    '''\n",
        "    cost_matrix = torch.zeros((L, k, len(possible)))\n",
        "    for i in range(L):\n",
        "        for j in range(k):\n",
        "            for m in range(len(possible)):\n",
        "                cost_matrix[i, j, m] = trace[i][j][m][1] + position[i, j, m]\n",
        "    '''\n",
        "    # Run the modified pipe_dp_differentiable function with the computed cost matrix\n",
        "    result_S, loss = pipe_dp_differentiable(L, cost_e_tensor, cost_c_tensor, k, B, position=position)\n",
        "    \n",
        "    # Perform backpropagation\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update the position tensor using gradient descent\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print the results\n",
        "    if epoch % 50 == 0:\n",
        "        print(f'Epoch {epoch}: Loss = {loss.item()}, Result S = {result_S}')\n",
        "\n",
        "print(f'Final Result S: {result_S}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMihGoIRlyC4",
        "outputId": "e06f4bff-f578-4f17-efa4-969c00e07639"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss = 2.0, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 50: Loss = 1.500000238418579, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 100: Loss = 1.0000007152557373, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 150: Loss = 0.500001072883606, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 200: Loss = 1.5497207641601562e-06, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 250: Loss = -0.4999980926513672, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 300: Loss = -0.999997615814209, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 350: Loss = -1.4999971389770508, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 400: Loss = -1.9999966621398926, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 450: Loss = -2.5000081062316895, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 500: Loss = -3.0000195503234863, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 550: Loss = -3.500030994415283, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 600: Loss = -4.00004243850708, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 650: Loss = -4.500053882598877, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 700: Loss = -5.000065326690674, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 750: Loss = -5.500076770782471, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 800: Loss = -6.000087738037109, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 850: Loss = -6.500099182128906, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 900: Loss = -7.000110626220703, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 950: Loss = -7.5001220703125, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1000: Loss = -8.000133514404297, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1050: Loss = -8.500144958496094, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1100: Loss = -9.00015640258789, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1150: Loss = -9.500167846679688, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1200: Loss = -10.000179290771484, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1250: Loss = -10.500190734863281, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1300: Loss = -11.000202178955078, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1350: Loss = -11.500213623046875, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1400: Loss = -12.000225067138672, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1450: Loss = -12.500236511230469, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1500: Loss = -13.000247955322266, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1550: Loss = -13.500259399414062, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1600: Loss = -14.00027084350586, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1650: Loss = -14.500282287597656, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1700: Loss = -15.000293731689453, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1750: Loss = -15.50030517578125, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1800: Loss = -16.000316619873047, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1850: Loss = -16.500328063964844, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1900: Loss = -17.00033950805664, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 1950: Loss = -17.500350952148438, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2000: Loss = -18.000362396240234, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2050: Loss = -18.50037384033203, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2100: Loss = -19.000385284423828, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2150: Loss = -19.500396728515625, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2200: Loss = -20.000408172607422, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2250: Loss = -20.50041961669922, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2300: Loss = -21.000431060791016, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2350: Loss = -21.500442504882812, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2400: Loss = -22.00045394897461, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2450: Loss = -22.500465393066406, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2500: Loss = -23.000476837158203, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2550: Loss = -23.50048828125, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2600: Loss = -24.000499725341797, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2650: Loss = -24.500511169433594, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2700: Loss = -25.00052261352539, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2750: Loss = -25.500534057617188, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2800: Loss = -26.000545501708984, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2850: Loss = -26.50055694580078, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2900: Loss = -27.000568389892578, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 2950: Loss = -27.500579833984375, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3000: Loss = -28.000591278076172, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3050: Loss = -28.50060272216797, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3100: Loss = -29.000614166259766, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3150: Loss = -29.500625610351562, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3200: Loss = -30.00063705444336, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3250: Loss = -30.500553131103516, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3300: Loss = -31.000469207763672, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3350: Loss = -31.500385284423828, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3400: Loss = -32.000301361083984, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3450: Loss = -32.50021743774414, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3500: Loss = -33.0001335144043, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3550: Loss = -33.50004959106445, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3600: Loss = -33.99996566772461, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3650: Loss = -34.499881744384766, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3700: Loss = -34.99979782104492, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3750: Loss = -35.49971389770508, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3800: Loss = -35.999629974365234, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3850: Loss = -36.49954605102539, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3900: Loss = -36.99946212768555, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 3950: Loss = -37.4993782043457, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4000: Loss = -37.99929428100586, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4050: Loss = -38.499210357666016, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4100: Loss = -38.99912643432617, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4150: Loss = -39.49904251098633, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4200: Loss = -39.998958587646484, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4250: Loss = -40.49887466430664, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4300: Loss = -40.9987907409668, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4350: Loss = -41.49870681762695, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4400: Loss = -41.99862289428711, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4450: Loss = -42.498538970947266, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4500: Loss = -42.99845504760742, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4550: Loss = -43.49837112426758, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4600: Loss = -43.998287200927734, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4650: Loss = -44.49820327758789, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4700: Loss = -44.99811935424805, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4750: Loss = -45.4980354309082, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4800: Loss = -45.99795150756836, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4850: Loss = -46.497867584228516, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4900: Loss = -46.99778366088867, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Epoch 4950: Loss = -47.49769973754883, Result S = tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "Final Result S: tensor([[1.0000e-06, 1.0000e-06],\n",
            "        [0.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 5.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oi49SwGOLQRN"
      },
      "outputs": [],
      "source": [
        "test_list = [(12, 4), (24, 4), (24,8), (24, 12), (36, 8)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuFDg9SsLQRN",
        "outputId": "ecfc2e26-ba46-4d58-90cd-3117c7abad35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "homo dp L=12 k=4 is [3, 3, 3, 3], minimum cost 12.0. Took time 0.011282682418823242\n",
            "homo bf L=12 k=4 is [3, 3, 3, 3], minimum cost 12.0. Took time 0.001417398452758789\n",
            "homo us L=12 k=4 is [3, 3, 3, 3], minimum cost 12.0. Took time 3.0279159545898438e-05\n",
            "homo dp L=24 k=4 is [6, 6, 6, 6], minimum cost 18.0. Took time 0.10501551628112793\n",
            "homo bf L=24 k=4 is [6, 6, 6, 6], minimum cost 18.0. Took time 0.021759510040283203\n",
            "homo us L=24 k=4 is [6, 6, 6, 6], minimum cost 18.0. Took time 2.288818359375e-05\n",
            "homo dp L=24 k=8 is [3, 3, 3, 3, 3, 3, 3, 3], minimum cost 20.0. Took time 0.19997739791870117\n",
            "homo bf L=24 k=8 is [3, 3, 3, 3, 3, 3, 3, 3], minimum cost 20.0. Took time 3.9657673835754395\n",
            "homo us L=24 k=8 is [3, 3, 3, 3, 3, 3, 3, 3], minimum cost 20.0. Took time 5.221366882324219e-05\n",
            "homo dp L=24 k=12 is [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], minimum cost 26.0. Took time 0.29858970642089844\n",
            "homo bf L=24 k=12 is [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], minimum cost 26.0. Took time 30.561776638031006\n",
            "homo us L=24 k=12 is [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], minimum cost 26.0. Took time 6.246566772460938e-05\n",
            "homo dp L=36 k=8 is [1, 5, 5, 5, 5, 5, 5, 5], minimum cost 24.0. Took time 0.7829232215881348\n",
            "homo bf L=36 k=8 is [1, 5, 5, 5, 5, 5, 5, 5], minimum cost 24.0. Took time 115.16702842712402\n",
            "homo us L=36 k=8 is [4, 4, 4, 4, 4, 4, 4, 8], minimum cost 30.0. Took time 5.984306335449219e-05\n"
          ]
        }
      ],
      "source": [
        "# homogeneous test\n",
        "for L, k in test_list:\n",
        "    cost_e = np.ones(L)\n",
        "    cost_c = np.ones((L-1, k-1)) * 2\n",
        "    time_s = time.time()\n",
        "    res = pipe_dp(L, cost_e, cost_c, k, 3)\n",
        "    print(f\"homo dp L={L} k={k} is {res[0]}, minimum cost {res[1]}. Took time {time.time() - time_s}\")\n",
        "    time_s = time.time()\n",
        "    res = brute_force(L, cost_e, cost_c, k, 3)\n",
        "    print(f\"homo bf L={L} k={k} is {res[0]}, minimum cost {res[1]}. Took time {time.time() - time_s}\")\n",
        "    time_s = time.time()\n",
        "    res = uniform_split(L, cost_e, cost_c, k, 3)\n",
        "    print(f\"homo us L={L} k={k} is {res[0]}, minimum cost {res[1]}. Took time {time.time() - time_s}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnA1NWzALQRO",
        "outputId": "bb4eab19-8f80-4b6c-e3cd-cbd35e489484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hete dp L=12 k=4 is [3, 3, 3, 3], minimum cost 70. Took time 0.05019879341125488\n",
            "hete bf L=12 k=4 is [3, 3, 3, 3], minimum cost 70. Took time 0.0013661384582519531\n",
            "hete us L=12 k=4 is [3, 3, 3, 3], minimum cost 70. Took time 1.9788742065429688e-05\n",
            "hete dp L=24 k=4 is [6, 6, 6, 6], minimum cost 115. Took time 0.7052814960479736\n",
            "hete bf L=24 k=4 is [6, 6, 6, 6], minimum cost 115. Took time 0.016564130783081055\n",
            "hete us L=24 k=4 is [6, 6, 6, 6], minimum cost 115. Took time 2.193450927734375e-05\n",
            "hete dp L=24 k=8 is [3, 4, 3, 2, 3, 3, 3, 3], minimum cost 95. Took time 1.4543581008911133\n",
            "hete bf L=24 k=8 is [3, 4, 3, 2, 3, 3, 3, 3], minimum cost 95. Took time 3.7701711654663086\n",
            "hete us L=24 k=8 is [3, 3, 3, 3, 3, 3, 3, 3], minimum cost 97. Took time 4.601478576660156e-05\n",
            "hete dp L=24 k=12 is [1, 2, 3, 2, 1, 2, 1, 3, 2, 3, 2, 2], minimum cost 104. Took time 1.8105647563934326\n",
            "hete bf L=24 k=12 is [1, 2, 3, 2, 1, 2, 1, 3, 2, 3, 2, 2], minimum cost 104. Took time 28.778594970703125\n",
            "hete us L=24 k=12 is [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], minimum cost 109. Took time 5.888938903808594e-05\n",
            "hete dp L=36 k=8 is [3, 5, 4, 5, 5, 6, 4, 4], minimum cost 117. Took time 7.158376693725586\n",
            "hete bf L=36 k=8 is [3, 5, 4, 5, 5, 6, 4, 4], minimum cost 117. Took time 108.56706666946411\n",
            "hete us L=36 k=8 is [4, 4, 4, 4, 4, 4, 4, 8], minimum cost 170. Took time 7.009506225585938e-05\n"
          ]
        }
      ],
      "source": [
        "# hetergeneous test\n",
        "for L, k in test_list:\n",
        "    cost_e = np.random.randint(low=5,high=10,size=L)\n",
        "    cost_c = np.random.randint(low=5,high=10,size=(L-1,k-1))\n",
        "    time_s = time.time()\n",
        "    res = pipe_dp(L, cost_e, cost_c, k, 3)\n",
        "    print(f\"hete dp L={L} k={k} is {res[0]}, minimum cost {res[1]}. Took time {time.time() - time_s}\")\n",
        "    time_s = time.time()\n",
        "    res = brute_force(L, cost_e, cost_c, k, 3)\n",
        "    print(f\"hete bf L={L} k={k} is {res[0]}, minimum cost {res[1]}. Took time {time.time() - time_s}\")\n",
        "    time_s = time.time()\n",
        "    res = uniform_split(L, cost_e, cost_c, k, 3)\n",
        "    print(f\"hete us L={L} k={k} is {res[0]}, minimum cost {res[1]}. Took time {time.time() - time_s}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCxoBCT3LQRO",
        "outputId": "f6ceffda-cc37-4a1e-e300-57ae8c050d44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hete dp L=12 k=4 is [3, 3, 3, 3], minimum cost 68. Took time 0.04140925407409668\n",
            "hete us L=12 k=4 is [3, 3, 3, 3], minimum cost 68. Took time 2.3603439331054688e-05\n",
            "hete dp L=24 k=12 is [2, 2, 2, 1, 2, 2, 2, 2, 3, 3, 1, 2], minimum cost 97. Took time 1.7796664237976074\n",
            "hete us L=24 k=12 is [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], minimum cost 107. Took time 4.839897155761719e-05\n",
            "hete dp L=36 k=8 is [4, 6, 4, 4, 4, 5, 5, 4], minimum cost 115. Took time 7.414276838302612\n",
            "hete us L=36 k=8 is [4, 4, 4, 4, 4, 4, 4, 8], minimum cost 161. Took time 4.6253204345703125e-05\n",
            "hete dp L=36 k=12 is [1, 3, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3], minimum cost 121. Took time 9.608815431594849\n",
            "hete us L=36 k=12 is [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], minimum cost 126. Took time 5.3882598876953125e-05\n",
            "hete dp L=48 k=12 is [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], minimum cost 129. Took time 30.9409818649292\n",
            "hete us L=48 k=12 is [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], minimum cost 129. Took time 5.507469177246094e-05\n",
            "hete dp L=48 k=24 is [3, 3, 3, 2, 3, 4, 2, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 4, 3], minimum cost 176. Took time 55.34712266921997\n",
            "hete us L=48 k=24 is [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], minimum cost 197. Took time 7.867813110351562e-05\n",
            "hete dp L=64 k=12 is [5, 6, 2, 6, 6, 6, 6, 5, 4, 6, 6, 6], minimum cost 148. Took time 97.49400663375854\n",
            "hete us L=64 k=12 is [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9], minimum cost 217. Took time 7.009506225585938e-05\n",
            "hete dp L=64 k=16 is [5, 4, 2, 2, 5, 4, 5, 2, 4, 4, 4, 5, 5, 4, 5, 4], minimum cost 157. Took time 130.8333797454834\n",
            "hete us L=64 k=16 is [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], minimum cost 180. Took time 6.508827209472656e-05\n",
            "hete dp L=128 k=32 is [4, 4, 4, 4, 5, 3, 5, 2, 4, 4, 5, 4, 5, 5, 5, 4, 1, 4, 5, 6, 5, 5, 6, 4, 4, 3, 1, 5, 4, 5, 2, 1], minimum cost 242. Took time 3688.281402349472\n",
            "hete us L=128 k=32 is [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], minimum cost 264. Took time 0.00010204315185546875\n",
            "hete dp L=128 k=12 is [10, 10, 10, 12, 11, 10, 11, 9, 11, 11, 12, 11], minimum cost 227. Took time 1504.3015270233154\n",
            "hete us L=128 k=12 is [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 18], minimum cost 319. Took time 7.486343383789062e-05\n",
            "hete dp L=128 k=50 is [1, 1, 3, 5, 4, 1, 1, 4, 1, 3, 1, 4, 4, 3, 1, 1, 4, 3, 1, 3, 2, 3, 1, 4, 5, 3, 2, 3, 3, 1, 1, 1, 3, 3, 3, 2, 4, 4, 4, 1, 2, 2, 4, 1, 2, 3, 1, 4, 5, 2], minimum cost 328. Took time 5430.115435838699\n",
            "hete us L=128 k=50 is [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 30], minimum cost 782. Took time 0.00014972686767578125\n"
          ]
        }
      ],
      "source": [
        "test_list_large = [(12, 4), (24, 12), (36, 8), (36, 12), (48,12), (48, 24), (64, 12), (64, 16), (128, 32), (128, 12), (128, 50)]\n",
        "for L, k in test_list_large:\n",
        "    cost_e = np.random.randint(low=5,high=10,size=L)\n",
        "    cost_c = np.random.randint(low=5,high=10,size=(L-1,k-1))\n",
        "    time_s = time.time()\n",
        "    res = pipe_dp(L, cost_e, cost_c, k, 3)\n",
        "    print(f\"hete dp L={L} k={k} is {res[0]}, minimum cost {res[1]}. Took time {time.time() - time_s}\")\n",
        "    time_s = time.time()\n",
        "    res = uniform_split(L, cost_e, cost_c, k, 3)\n",
        "    print(f\"hete us L={L} k={k} is {res[0]}, minimum cost {res[1]}. Took time {time.time() - time_s}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E71Et0BLQRP",
        "outputId": "be02c1e5-8523-4446-809a-3eca7421d652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "homo dp L=16 k=8 is [2, 2, 2, 2, 2, 2, 2, 2], minimum cost 18.0. Took time 0.05113816261291504\n",
            "homo bf L=16 k=8 is [2, 2, 2, 2, 2, 2, 2, 2], minimum cost 18.0. Took time 0.09984564781188965\n",
            "homo dp L=17 k=8 is [1, 1, 1, 2, 3, 3, 3, 3], minimum cost 20.0. Took time 0.06062602996826172\n",
            "homo bf L=17 k=8 is [1, 1, 1, 2, 3, 3, 3, 3], minimum cost 20.0. Took time 0.17916107177734375\n",
            "homo dp L=18 k=8 is [1, 1, 1, 3, 3, 3, 3, 3], minimum cost 20.0. Took time 0.07352972030639648\n",
            "homo bf L=18 k=8 is [1, 1, 1, 3, 3, 3, 3, 3], minimum cost 20.0. Took time 0.30548691749572754\n",
            "homo dp L=19 k=8 is [1, 1, 2, 3, 3, 3, 3, 3], minimum cost 20.0. Took time 0.08911275863647461\n",
            "homo bf L=19 k=8 is [1, 1, 2, 3, 3, 3, 3, 3], minimum cost 20.0. Took time 0.5053002834320068\n",
            "homo dp L=20 k=8 is [1, 1, 3, 3, 3, 3, 3, 3], minimum cost 20.0. Took time 0.10455751419067383\n",
            "homo bf L=20 k=8 is [1, 1, 3, 3, 3, 3, 3, 3], minimum cost 20.0. Took time 0.7985565662384033\n",
            "homo dp L=21 k=8 is [1, 2, 3, 3, 3, 3, 3, 3], minimum cost 20.0. Took time 0.1241300106048584\n",
            "homo bf L=21 k=8 is [1, 2, 3, 3, 3, 3, 3, 3], minimum cost 20.0. Took time 1.2353487014770508\n",
            "homo dp L=22 k=8 is [1, 3, 3, 3, 3, 3, 3, 3], minimum cost 20.0. Took time 0.14544916152954102\n",
            "homo bf L=22 k=8 is [1, 3, 3, 3, 3, 3, 3, 3], minimum cost 20.0. Took time 1.8621459007263184\n",
            "homo dp L=23 k=8 is [2, 3, 3, 3, 3, 3, 3, 3], minimum cost 20.0. Took time 0.16782760620117188\n",
            "homo bf L=23 k=8 is [2, 3, 3, 3, 3, 3, 3, 3], minimum cost 20.0. Took time 2.7482845783233643\n",
            "homo dp L=24 k=8 is [3, 3, 3, 3, 3, 3, 3, 3], minimum cost 20.0. Took time 0.1974644660949707\n",
            "homo bf L=24 k=8 is [3, 3, 3, 3, 3, 3, 3, 3], minimum cost 20.0. Took time 3.9475131034851074\n"
          ]
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "test_list = [(16,8), (17, 8), (18,8), (19,8), (20, 8), (21,8), (22,8), (23, 8),(24,8)]\n",
        "dp_time = []\n",
        "bf_time = []\n",
        "\n",
        "# homogeneous test\n",
        "for L, k in test_list:\n",
        "    cost_e = np.ones(L)\n",
        "    cost_c = np.ones((L-1, k-1)) * 2\n",
        "    time_s = time.time()\n",
        "    res = pipe_dp(L, cost_e, cost_c, k, 3)\n",
        "    time_elapsed = time.time() - time_s\n",
        "    dp_time.append(time_elapsed)\n",
        "    print(f\"homo dp L={L} k={k} is {res[0]}, minimum cost {res[1]}. Took time {time_elapsed}\")\n",
        "    time_s = time.time()\n",
        "    res = brute_force(L, cost_e, cost_c, k, 3)\n",
        "    time_elapsed = time.time() - time_s\n",
        "    bf_time.append(time_elapsed)\n",
        "    print(f\"homo bf L={L} k={k} is {res[0]}, minimum cost {res[1]}. Took time {time_elapsed}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "69nTOIEBLQRP",
        "outputId": "3b7f75de-e739-4eb9-ccc5-f5711f0b1b63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f35ee31add0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot([16,17, 18, 19, 20, 21, 22, 23, 24], dp_time, label=\"ours\")\n",
        "plt.plot([16,17, 18, 19, 20, 21, 22, 23, 24], bf_time, label=\"brute force\")\n",
        "plt.xlabel(\"number of layers\")\n",
        "plt.ylabel(\"runtime\")\n",
        "plt.legend(loc=\"best\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7_vTnJRLQRP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}